## Lecture 8: Using Models to Create Forecasts {#forecasts}
<!-- reference with [Forecasts](#forecasts) -->

### Making forecasts


### Expected Value of Perfect Information (EVPI) 

<!-- Hoa's AF video -->
<!-- Cory's EVPI video -->

There is always some degree of uncertainty surrounding a decision, because there is always a chance that the decision turns out to be wrong. EVPI measures the expected cost of that uncertainty where access to perfect information can eliminate the possibility of making the wrong decision. We do this with a payoff matrix {\Rij} in which the row index {\i} describes a choice that must be made by the decision maker, while the column index {\j} describes a random variable that the decision maker does not yet have knowledge of, that has probability {\pj} of being in state {\j}. If the decision maker is to choose {\i} without knowing the value of {\j}, the best choice is the one that maximizes the expected value:

{\displaystyle {\mbox{EMV}}=\max _{i}\sum _{j}p_{j}R_{ij}}{\displaystyle {\mbox{EMV}}=\max _{i}\sum _{j}p_{j}R_{ij}}
where

{\displaystyle \sum _{j}p_{j}R_{ij}}{\displaystyle \sum _{j}p_{j}R_{ij}}
is the expected payoff for action {\i} i.e. the expectation value, and

{\displaystyle {\mbox{EMV}}=\max _{i}}{\displaystyle {\mbox{EMV}}=\max _{i}}
is choosing the maximum of these expectations for all available actions. On the other hand, with perfect knowledge of {\j}, the player may choose a value of {\i} that optimizes the expectation for that specific {\j}. Therefore, the expected value given perfect information is

{\displaystyle {\mbox{EV}}|{\mbox{PI}}=\sum _{j}p_{j}(\max _{i}R_{ij}),}{\displaystyle {\mbox{EV}}|{\mbox{PI}}=\sum _{j}p_{j}(\max _{i}R_{ij}),}
where {\displaystyle p_{j}}p_{j} is the probability that the system is in state {\j}, and {\displaystyle R_{ij}}R_{ij} is the pay-off if one follows action {\i} while the system is in state {\j}. Here {\displaystyle (\max _{i}R_{ij}),}{\displaystyle (\max _{i}R_{ij}),} indicates the best choice of action {\i} for each state {\j}.

The expected value of perfect information is the difference between these two quantities,

{\displaystyle {\mbox{EVPI}}={\mbox{EV}}|{\mbox{PI}}-{\mbox{EMV}}.}{\displaystyle {\mbox{EVPI}}={\mbox{EV}}|{\mbox{PI}}-{\mbox{EMV}}.}

This difference describes, in expectation, how much larger a value the player can hope to obtain by knowing j and picking the best i for that j, as compared to picking a value of i before j is known. Since EV|PI is necessarily greater than or equal to EMV, EVPI is always non-negative.

### Projection to Latent Structures

The general underlying model of multivariate PLS is

{\displaystyle X=TP^{\mathrm {T} }+E}{\displaystyle X=TP^{\mathrm {T} }+E}
{\displaystyle Y=UQ^{\mathrm {T} }+F}{\displaystyle Y=UQ^{\mathrm {T} }+F}

where X is an {\displaystyle n\times m}n\times m matrix of predictors, Y is an {\displaystyle n\times p}n\times p matrix of responses; T and U are {\displaystyle n\times l}n \times l matrices that are, respectively, projections of X (the X score, component or factor matrix) and projections of Y (the Y scores); P and Q are, respectively, {\displaystyle m\times l}m \times l and {\displaystyle p\times l}p \times l orthogonal loading matrices; and matrices E and F are the error terms, assumed to be independent and identically distributed random normal variables. The decomposition of X and Y are made so as to maximize the covariance between T and U. Read more in ['A Simple Explanation of Partial Least Squares' by Kee Siong Ng](http://users.cecs.anu.edu.au/~kee/pls.pdf).

### Varible Importance in the Projection (VIP)

Variable Importance in Projection (VIP) scores estimate the importance of each variable in the projection used in a PLS mode. A variable with a VIP Score close to or greater than 1 (one) can be considered important in given model. Variables with VIP scores significantly less than 1 (one) are less important and might be good candidates for exclusion from the model.

The input is a PLS model and the output is a set of column vectors equal in length to the number of variables included in the model..

### Group discussion reading: 

- Tetlock, Philip E., and Dan Gardner. Superforecasting: The Art and Science of Prediction. New York, NY: Crown Publishers, 2015.(Chapter 1. An Optimistic Skeptic) 
